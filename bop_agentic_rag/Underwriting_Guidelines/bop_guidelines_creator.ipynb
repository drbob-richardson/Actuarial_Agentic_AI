{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG7Zusv3q7aY",
        "outputId": "98458b31-1223-4022-ede8-840b507066f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.17)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.15-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, pypdf, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-openai, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.11.0 httpx-sse-0.4.0 langchain-community-0.3.23 langchain-openai-0.3.15 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 pypdf-5.4.0 python-dotenv-1.1.0 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install langchain openai faiss-cpu pypdf langchain-openai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIk8kDs7rDXG"
      },
      "outputs": [],
      "source": [
        "# Setup environment and API key\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fouiCbtcrlV-"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import glob\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_TSYlF8uqW-",
        "outputId": "489ad654-0a21-4b37-c61f-4dd0a8c7a1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5 PDF files: ['AFS_BOP_General_Guidelines_InfoSheet_MKT5674.pdf', 'ARIC Underwriting Guide 7-2012.pdf', 'Attune-Appetite-Guide.pdf', 'Businessowners-Policy-Cov-Robert-Richardson-2.pdf', 'UnderwritingGuidelines-BusinessOwners-2.pdf']\n",
            "Loaded 1 pages from AFS_BOP_General_Guidelines_InfoSheet_MKT5674.pdf\n",
            "Loaded 43 pages from ARIC Underwriting Guide 7-2012.pdf\n",
            "Loaded 3 pages from Attune-Appetite-Guide.pdf\n",
            "Loaded 414 pages from Businessowners-Policy-Cov-Robert-Richardson-2.pdf\n",
            "Loaded 9 pages from UnderwritingGuidelines-BusinessOwners-2.pdf\n",
            "Total documents loaded: 470\n"
          ]
        }
      ],
      "source": [
        "# Load PDF documents\n",
        "pdf_files = glob.glob(\"*.pdf\")\n",
        "print(f\"Found {len(pdf_files)} PDF files: {pdf_files}\")\n",
        "\n",
        "# Load and combine documents\n",
        "documents = []\n",
        "for pdf_file in pdf_files:\n",
        "    loader = PyPDFLoader(pdf_file)\n",
        "    docs = loader.load()\n",
        "    documents.extend(docs)\n",
        "    print(f\"Loaded {len(docs)} pages from {pdf_file}\")\n",
        "\n",
        "print(f\"Total documents loaded: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8K9EIuRrrkI",
        "outputId": "312ac77c-3b84-4534-e2a5-0082ab009209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split documents into 1157 chunks.\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "doc_chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Split documents into {len(doc_chunks)} chunks.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwzsOxKvruZW"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings_openai = OpenAIEmbeddings()\n",
        "\n",
        "vectorstore_openai = FAISS.from_documents(doc_chunks, embeddings_openai)\n",
        "vectorstore_openai.save_local(\"faiss_bop_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvjwzAqMlrKB"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "retriever_coverage = vectorstore_openai.as_retriever(search_kwargs={\"k\": 5})\n",
        "retriever_underwriting = vectorstore_openai.as_retriever(search_kwargs={\"k\": 8})\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
        "\n",
        "def agentic_pipeline(business_type):\n",
        "    docs_coverage = retriever_coverage.get_relevant_documents(business_type)\n",
        "    docs_underwriting = retriever_underwriting.get_relevant_documents(business_type)\n",
        "\n",
        "    coverage_text = \"\\n\".join([doc.page_content for doc in docs_coverage])\n",
        "    underwriting_text = \"\\n\".join([doc.page_content for doc in docs_underwriting])\n",
        "\n",
        "    steps = {}\n",
        "\n",
        "    # Step 1: Thoroughly describe business\n",
        "    prompt_step1 = PromptTemplate(\n",
        "        input_variables=[\"business_type\"],\n",
        "        template=\"\"\"\n",
        "        Thoroughly describe the type of work done by small businesses classified as {business_type}. Include where the work is performed, typical customers, and a typical workday.\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step1\"] = (prompt_step1 | llm).invoke({\"business_type\": business_type}).content\n",
        "\n",
        "    # Step 2: Property risks\n",
        "    prompt_step2 = PromptTemplate(\n",
        "        input_variables=[\"business_description\", \"coverage_text\"],\n",
        "        template=\"\"\"\n",
        "        Using the description of the business:\n",
        "        {business_description}\n",
        "\n",
        "        Identify property insurance risks for this class, referencing this coverage guide:\n",
        "        {coverage_text}\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step2\"] = (prompt_step2 | llm).invoke({\"business_description\": steps[\"step1\"], \"coverage_text\": coverage_text}).content\n",
        "\n",
        "    # Step 3: Property coverage recommendations\n",
        "    prompt_step3 = PromptTemplate(\n",
        "        input_variables=[\"property_risks\", \"coverage_text\"],\n",
        "        template=\"\"\"\n",
        "        Based on the identified property risks:\n",
        "        {property_risks}\n",
        "\n",
        "        Recommend essential property coverages, including optional coverages, referring to this coverage guide:\n",
        "        {coverage_text}\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step3\"] = (prompt_step3 | llm).invoke({\"property_risks\": steps[\"step2\"], \"coverage_text\": coverage_text}).content\n",
        "\n",
        "    # Step 4: Liability risks\n",
        "    prompt_step4 = PromptTemplate(\n",
        "        input_variables=[\"business_description\", \"coverage_text\"],\n",
        "        template=\"\"\"\n",
        "        Using the description of the business:\n",
        "        {business_description}\n",
        "\n",
        "        Identify general liability insurance risks for this class, referencing this coverage guide:\n",
        "        {coverage_text}\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step4\"] = (prompt_step4 | llm).invoke({\"business_description\": steps[\"step1\"], \"coverage_text\": coverage_text}).content\n",
        "\n",
        "    # Step 5: Liability coverage recommendations\n",
        "    prompt_step5 = PromptTemplate(\n",
        "        input_variables=[\"liability_risks\", \"coverage_text\"],\n",
        "        template=\"\"\"\n",
        "        Based on the identified liability risks:\n",
        "        {liability_risks}\n",
        "\n",
        "        Recommend essential liability coverages, including optional coverages, referring to this coverage guide:\n",
        "        {coverage_text}\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step5\"] = (prompt_step5 | llm).invoke({\"liability_risks\": steps[\"step4\"], \"coverage_text\": coverage_text}).content\n",
        "\n",
        "    # Step 6: Underwriting appetite guidelines\n",
        "    prompt_step6 = PromptTemplate(\n",
        "        input_variables=[\"previous_steps\", \"underwriting_text\"],\n",
        "        template=\"\"\"\n",
        "        Using information:\n",
        "        {previous_steps}\n",
        "\n",
        "        Develop concise underwriting appetite guidelines (preferred, acceptable, not acceptable categories), requirements (mandatory or preferred), and out-of-appetite optional coverages, referencing this underwriting guide:\n",
        "        {underwriting_text}\n",
        "        \"\"\"\n",
        "    )\n",
        "    combined_steps_1_to_5 = '\\n\\n'.join([steps[f\"step{i}\"] for i in range(1, 6)])\n",
        "    steps[\"step6\"] = (prompt_step6 | llm).invoke({\"previous_steps\": combined_steps_1_to_5, \"underwriting_text\": underwriting_text}).content\n",
        "\n",
        "    # Step 7: Coverage restrictions with detailed reasoning\n",
        "    prompt_step7 = PromptTemplate(\n",
        "        input_variables=[\"previous_steps\"],\n",
        "        template=\"\"\"\n",
        "        Based on the following information:\n",
        "        {previous_steps}\n",
        "\n",
        "        Determine if any coverage restrictions are necessary. List each restriction clearly, providing detailed reasoning on why each restriction is necessary.\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step7\"] = (prompt_step7 | llm).invoke({\"previous_steps\": combined_steps_1_to_5}).content\n",
        "\n",
        "    # Step 8: Summary of unintuitive risks\n",
        "    prompt_step8 = PromptTemplate(\n",
        "        input_variables=[\"previous_steps\"],\n",
        "        template=\"\"\"\n",
        "        Summarize any unintuitive risks associated with insuring this class of business:\n",
        "        {previous_steps}\n",
        "\n",
        "        Limit your response to 1-3 sentences.\n",
        "        \"\"\"\n",
        "    )\n",
        "    steps[\"step8\"] = (prompt_step8 | llm).invoke({\"previous_steps\": combined_steps_1_to_5}).content\n",
        "\n",
        "    # Step 9: Final concise review\n",
        "    prompt_step9 = PromptTemplate(\n",
        "        input_variables=[\"steps_6_8\"],\n",
        "        template=\"\"\"\n",
        "        Review and refine the following underwriting guidelines for consistency, relevance, and conciseness. Ensure all restrictions clearly include detailed reasoning:\n",
        "        {steps_6_8}\n",
        "\n",
        "        Provide the final, concise underwriting appetite guideline clearly in Markdown format.\n",
        "        \"\"\"\n",
        "    )\n",
        "    combined_steps_6_to_8 = '\\n\\n'.join([steps[f\"step{i}\"] for i in range(6, 9)])\n",
        "    final_guidelines = (prompt_step9 | llm).invoke({\"steps_6_8\": combined_steps_6_to_8}).content\n",
        "\n",
        "    markdown_output = f\"## {business_type}\\n\\n{final_guidelines}\\n\"\n",
        "\n",
        "    return markdown_output\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckM-2yaPsmEv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Initialize markdown file with YAML front matter\n",
        "markdown_filename = \"bop_guidelines.md\"\n",
        "\n",
        "front_matter = \"\"\"---\n",
        "title: \"Business Owners Policy Underwriting Guidelines\"\n",
        "author: \"Automated Agentic Underwriting Assistant\"\n",
        "date: \"2024-04-28\"\n",
        "output: pdf_document\n",
        "---\\n\\n\"\"\"\n",
        "\n",
        "with open(markdown_filename, \"w\") as md_file:\n",
        "    md_file.write(front_matter)\n",
        "\n",
        "# Read business types from file and apply agentic pipeline\n",
        "with open(\"bop_categories.txt\", \"r\") as categories_file:\n",
        "    business_types = [line.strip() for line in categories_file if line.strip()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iBiD3WHSpJx",
        "outputId": "151c9c7f-682e-4816-bea8-9c5f986de315"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<enumerate at 0x78db6791e430>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMzXOH3is2mk",
        "outputId": "c87c6d16-1f0a-415b-e94f-884ce5d9d4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 1/127: Accounting & Financial Services\n",
            "Processing 2/127: Actuarial & Appraisal Services\n",
            "Processing 3/127: Advertising Agencies\n",
            "Processing 4/127: Air Conditioning & Heating (Sales/Service/Manufacturing)\n",
            "Processing 5/127: Alarm System Installation\n",
            "Processing 6/127: Ambulance & Emergency Services\n",
            "Processing 7/127: Animal & Veterinary Services\n",
            "Processing 8/127: Answering & Telemarketing Services\n",
            "Processing 9/127: Antique & Collectible Stores\n",
            "Processing 10/127: Appliance Sales & Repair\n",
            "Processing 11/127: Army/Navy/Military Surplus Stores\n",
            "Processing 12/127: Art Galleries & Art Supply Stores\n",
            "Processing 13/127: Artificial Flowers & Floral Supplies\n",
            "Processing 14/127: Artists & Craft Studios\n",
            "Processing 15/127: Asphalt & Paving Services\n",
            "Processing 16/127: Assembly & Packaging Services\n",
            "Processing 17/127: Audio & Visual Equipment Sales/Service\n",
            "Processing 18/127: Auto Parts & Accessories\n",
            "Processing 19/127: Auto Services & Repair (including body shops)\n",
            "Processing 20/127: Bakeries & Bagel Shops\n",
            "Processing 21/127: Banks & Credit Unions\n",
            "Processing 22/127: Barber & Beauty Salons\n"
          ]
        }
      ],
      "source": [
        "# Loop through each business type and append to markdown file\n",
        "for idx, business_type in enumerate(business_types):\n",
        "    print(f\"Processing {idx+1}/{len(business_types)}: {business_type}\")\n",
        "\n",
        "    markdown_section = agentic_pipeline(business_type)\n",
        "\n",
        "    with open(markdown_filename, \"a\") as md_file:\n",
        "        md_file.write(markdown_section)\n",
        "        md_file.write(\"\\n\\n---\\n\\n\")\n",
        "\n",
        "print(f\"Markdown guidelines successfully created in '{markdown_filename}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyK2iZHMTJL2",
        "outputId": "89167b73-aebb-4b8d-be97-5a0a4706af2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 38/127: Cemeteries & Funeral Services\n",
            "Processing 39/127: Churches & Religious Organizations\n",
            "Processing 40/127: Clothing & Apparel (Retail & Wholesale)\n",
            "Processing 41/127: Clubs & Recreation Facilities\n",
            "Processing 42/127: Coffee Shops & Tea Houses\n",
            "Processing 43/127: Computer & Technology Services\n",
            "Processing 44/127: Concrete & Masonry Services\n",
            "Processing 45/127: Convenience Stores\n",
            "Processing 46/127: Cosmetics & Toiletries\n",
            "Processing 47/127: Countertop & Surface Installation\n",
            "Processing 48/127: Craft & Hobby Stores\n",
            "Processing 49/127: Dairy & Ice Cream Shops\n",
            "Processing 50/127: Dance, Drama, & Music Schools\n",
            "Processing 51/127: Day Care & Child Care Centers\n",
            "Processing 52/127: Delicatessens & Sandwich Shops\n",
            "Processing 53/127: Department & Discount Stores\n",
            "Processing 54/127: Detective & Security Services\n",
            "Processing 55/127: Diaper & Linen Services\n",
            "Processing 56/127: Door & Window Installation/Sales\n",
            "Processing 57/127: Dry Cleaning & Laundry Services\n",
            "Processing 58/127: Educational & School Supply Stores\n",
            "Processing 59/127: Electrical Equipment & Supplies\n",
            "Processing 60/127: Electronics Stores & Repair\n",
            "Processing 61/127: Embroidery & Custom Apparel\n",
            "Processing 62/127: Employment Agencies\n",
            "Processing 63/127: Engineering & Surveying\n",
            "Processing 64/127: Fabric & Sewing Stores\n",
            "Processing 65/127: Fast Food & Family Restaurants\n",
            "Processing 66/127: Financial Planners & Investment Firms\n",
            "Processing 67/127: Floor Covering & Carpet Installation\n",
            "Processing 68/127: Florists\n",
            "Processing 69/127: Food & Grocery Stores\n",
            "Processing 70/127: Dessert Shops\n",
            "Processing 71/127: Fruit & Vegetable Markets\n",
            "Processing 72/127: Furniture Stores & Installation\n",
            "Processing 73/127: Garden & Landscaping Services\n",
            "Processing 74/127: General Contractors & Builders\n",
            "Processing 75/127: Gift & Souvenir Shops\n",
            "Processing 76/127: Glass & Window Services\n",
            "Processing 77/127: Golf & Sporting Equipment Stores\n",
            "Processing 78/127: Graphic Design & Commercial Artists\n",
            "Processing 79/127: Hardware & Home Improvement Stores\n",
            "Processing 80/127: Health Food & Vitamin Stores\n",
            "Processing 81/127: Heating & Refrigeration Services\n",
            "Processing 82/127: Hobby & Model Shops\n",
            "Processing 83/127: Hotels, Motels, Bed & Breakfasts\n",
            "Processing 84/127: Interior Decorating & Design\n",
            "Processing 85/127: Janitorial & Cleaning Services\n",
            "Processing 86/127: Jewelry & Watch Stores\n",
            "Processing 87/127: Kitchen & Home Accessories Stores\n",
            "Processing 88/127: Laundromats & Laundry Services\n",
            "Processing 89/127: Leather Goods & Luggage Stores\n",
            "Processing 90/127: Libraries & Museums\n",
            "Processing 91/127: Lighting Fixtures & Supplies\n",
            "Processing 92/127: Locksmiths\n",
            "Processing 93/127: Mail & Packaging Services\n",
            "Processing 94/127: Medical & Dental Offices\n",
            "Processing 95/127: Medical & Hospital Supply Stores\n",
            "Processing 96/127: Monument & Tombstone Sales\n",
            "Processing 97/127: Musical Instrument Sales & Repair\n",
            "Processing 98/127: Office Supplies & Equipment\n",
            "Processing 99/127: Optical Goods & Services\n",
            "Processing 100/127: Paint & Wallpaper Stores\n",
            "Processing 101/127: Pet Stores & Pet Grooming\n",
            "Processing 102/127: Photography Studios & Supplies\n",
            "Processing 103/127: Plumbing & HVAC Contractors\n",
            "Processing 104/127: Post Office & Shipping Centers\n",
            "Processing 105/127: Printing & Copying Services\n",
            "Processing 106/127: Real Estate Agencies\n",
            "Processing 107/127: Restaurants (Various Types: Full Service, Limited Service, Fast Food)\n",
            "Processing 108/127: Self Storage Facilities\n",
            "Processing 109/127: Shoe Stores & Repair\n",
            "Processing 110/127: Shopping Centers & Strip Malls\n",
            "Processing 111/127: Sporting Goods Stores\n",
            "Processing 112/127: Stationery & Paper Products\n",
            "Processing 113/127: Supermarkets & Grocery Stores\n",
            "Processing 114/127: Tailors & Dressmakers\n",
            "Processing 115/127: Tax Preparation & Accounting\n",
            "Processing 116/127: Tire & Automotive Centers\n",
            "Processing 117/127: Toy Stores\n",
            "Processing 118/127: Travel Agencies\n",
            "Processing 119/127: Trophy & Awards Shops\n",
            "Processing 120/127: Upholstery Services\n",
            "Processing 121/127: Vacuum Cleaner Sales & Service\n",
            "Processing 122/127: Variety & General Merchandise Stores\n",
            "Processing 123/127: Video & Media Stores\n",
            "Processing 124/127: Web Design & Online Services\n",
            "Processing 125/127: Wedding Services & Chapels\n",
            "Processing 126/127: Window Treatments & Blinds\n",
            "Processing 127/127: Woodworking & Carpentry\n",
            "Markdown guidelines successfully appended from business #38 onward in 'bop_guidelines.md'.\n"
          ]
        }
      ],
      "source": [
        "start_idx = 37  # zero-indexed, so 37 means starting from the 38th business\n",
        "for idx, business_type in enumerate(business_types[start_idx:], start=start_idx + 1):\n",
        "    print(f\"Processing {idx}/{len(business_types)}: {business_type}\")\n",
        "\n",
        "    markdown_section = agentic_pipeline(business_type)\n",
        "\n",
        "    with open(markdown_filename, \"a\") as md_file:\n",
        "        md_file.write(markdown_section)\n",
        "        md_file.write(\"\\n\\n---\\n\\n\")\n",
        "\n",
        "print(f\"Markdown guidelines successfully appended from business #{start_idx + 1} onward in '{markdown_filename}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzNbR9R0ZWKS"
      },
      "outputs": [],
      "source": [
        "# Enhanced global requirements generation pipeline\n",
        "\n",
        "# Step 1: Initial identification of global underwriting requirements\n",
        "initial_prompt = PromptTemplate(\n",
        "    input_variables=[\"retrieved_docs\"],\n",
        "    template=\"\"\"\n",
        "    Based on the following underwriting guidelines, list concise and universally applicable underwriting requirements that apply broadly to all business types.\n",
        "    Clearly number your response.\n",
        "\n",
        "    Guidelines:\n",
        "    {retrieved_docs}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "initial_chain = (\n",
        "    {\"retrieved_docs\": lambda _: \"\\n\".join(\n",
        "        [doc.page_content for doc in retriever.get_relevant_documents(\"global underwriting requirements\")])}\n",
        "    | initial_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "initial_requirements_text = initial_chain.invoke(\"\")\n",
        "\n",
        "# Clearly print initial list for verification\n",
        "print(\"Initial Global Requirements Identified:\")\n",
        "print(initial_requirements_text)\n",
        "\n",
        "# Parse requirements list\n",
        "requirements_list = [line.strip() for line in initial_requirements_text.split('\\n') if line.strip()]\n",
        "\n",
        "# Step 2: Detailed Explanation with consistent categorization and reasoning\n",
        "detail_prompt = PromptTemplate(\n",
        "    input_variables=[\"requirement\", \"retrieved_docs\"],\n",
        "    template=\"\"\"\n",
        "    Clearly define the following underwriting requirement for a Business Owner Policy Guide. Include:\n",
        "\n",
        "    1. Detailed description of the requirement.\n",
        "    2. Categorization (mandatory or recommended).\n",
        "    3. Explicit and consistent reasoning explaining why this requirement is necessary from an underwriting perspective.\n",
        "    4. Any specific underwriting outcomes or risks addressed by this requirement.\n",
        "\n",
        "    Requirement:\n",
        "    {requirement}\n",
        "\n",
        "    Guidelines:\n",
        "    {retrieved_docs}\n",
        "\n",
        "    Respond in clear and structured Markdown format.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "detailed_responses = []\n",
        "\n",
        "for idx, requirement in enumerate(requirements_list):\n",
        "    print(f\"Refining global requirement {idx+1}/{len(requirements_list)}\")\n",
        "\n",
        "    retrieved_docs = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(requirement)])\n",
        "\n",
        "    detailed_chain = (\n",
        "        {\"requirement\": lambda _: requirement, \"retrieved_docs\": lambda _: retrieved_docs}\n",
        "        | detail_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    detailed_response = detailed_chain.invoke({})\n",
        "    detailed_responses.append(detailed_response)\n",
        "\n",
        "# Step 3: Validation and Consistency Check\n",
        "final_review_prompt = PromptTemplate(\n",
        "    input_variables=[\"detailed_requirements\"],\n",
        "    template=\"\"\"\n",
        "    Review the following detailed underwriting guidelines:\n",
        "\n",
        "    {detailed_requirements}\n",
        "\n",
        "    Validate each guideline ensuring:\n",
        "    - Consistency in structure and categorization.\n",
        "    - Explicit reasoning clearly tied to underwriting relevance.\n",
        "    - Removal of any redundant or irrelevant content.\n",
        "\n",
        "    Provide a final, refined, and concise list of global underwriting guidelines in Markdown format.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "final_review_chain = (\n",
        "    {\"detailed_requirements\": lambda _: \"\\n\\n\".join(detailed_responses)}\n",
        "    | final_review_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_refined_guidelines = final_review_chain.invoke({})\n",
        "\n",
        "# Append refined global guidelines to markdown\n",
        "with open(markdown_filename, \"a\") as md_file:\n",
        "    md_file.write(\"## Global Underwriting Requirements\\n\\n\")\n",
        "    md_file.write(final_refined_guidelines)\n",
        "    md_file.write(\"\\n\\n---\\n\\n\")\n",
        "\n",
        "print(f\"Refined global underwriting requirements successfully appended to '{markdown_filename}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUt1kzRsZz7j"
      },
      "outputs": [],
      "source": [
        "# Parse requirements list\n",
        "requirements_list = [line.strip() for line in initial_requirements_text.split('\\n') if line.strip()]\n",
        "\n",
        "# Step 2: Detailed Explanation with consistent categorization and reasoning\n",
        "detail_prompt = PromptTemplate(\n",
        "    input_variables=[\"requirement\", \"retrieved_docs\"],\n",
        "    template=\"\"\"\n",
        "    Clearly define the following underwriting requirement for a Business Owner Policy Guide. Include:\n",
        "\n",
        "    1. Detailed description of the requirement.\n",
        "    2. Categorization (mandatory or recommended).\n",
        "    3. Explicit and consistent reasoning explaining why this requirement is necessary from an underwriting perspective.\n",
        "    4. Any specific underwriting outcomes or risks addressed by this requirement.\n",
        "\n",
        "    Requirement:\n",
        "    {requirement}\n",
        "\n",
        "    Guidelines:\n",
        "    {retrieved_docs}\n",
        "\n",
        "    Respond in clear and structured Markdown format.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "detailed_responses = []\n",
        "\n",
        "for idx, requirement in enumerate(requirements_list):\n",
        "    print(f\"Refining global requirement {idx+1}/{len(requirements_list)}\")\n",
        "\n",
        "    retrieved_docs = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(requirement)])\n",
        "\n",
        "    detailed_chain = (\n",
        "        {\"requirement\": lambda _: requirement, \"retrieved_docs\": lambda _: retrieved_docs}\n",
        "        | detail_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    detailed_response = detailed_chain.invoke({})\n",
        "    detailed_responses.append(detailed_response)\n",
        "\n",
        "# Step 3: Validation and Consistency Check\n",
        "final_review_prompt = PromptTemplate(\n",
        "    input_variables=[\"detailed_requirements\"],\n",
        "    template=\"\"\"\n",
        "    Review the following detailed underwriting guidelines:\n",
        "\n",
        "    {detailed_requirements}\n",
        "\n",
        "    Validate each guideline ensuring:\n",
        "    - Consistency in structure and categorization.\n",
        "    - Explicit reasoning clearly tied to underwriting relevance.\n",
        "    - Removal of any redundant or irrelevant content.\n",
        "\n",
        "    Provide a final, refined, and concise list of global underwriting guidelines in Markdown format.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "final_review_chain = (\n",
        "    {\"detailed_requirements\": lambda _: \"\\n\\n\".join(detailed_responses)}\n",
        "    | final_review_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_refined_guidelines = final_review_chain.invoke({})\n",
        "\n",
        "# Append refined global guidelines to markdown\n",
        "with open(markdown_filename, \"a\") as md_file:\n",
        "    md_file.write(\"## Global Underwriting Requirements\\n\\n\")\n",
        "    md_file.write(final_refined_guidelines)\n",
        "    md_file.write(\"\\n\\n---\\n\\n\")\n",
        "\n",
        "print(f\"Refined global underwriting requirements successfully appended to '{markdown_filename}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSEAsprjcIV3"
      },
      "outputs": [],
      "source": [
        "# Additional code to label each business and append a summary table\n",
        "import re\n",
        "import random\n",
        "\n",
        "# Read the existing markdown file to extract business names\n",
        "with open(\"bop_guidelines.md\", \"r\") as md_file:\n",
        "    markdown_content = md_file.read()\n",
        "\n",
        "# Extract business names from markdown headers\n",
        "business_names = re.findall(r'^##\\s+(.*)$', markdown_content, re.MULTILINE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drV0muxKcL_r"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define prompt to categorize each business\n",
        "status_prompt = PromptTemplate(\n",
        "    input_variables=[\"business_name\", \"business_details\"],\n",
        "    template=\"\"\"\n",
        "    Review the underwriting details for the following business:\n",
        "\n",
        "    Business Name:\n",
        "    {business_name}\n",
        "\n",
        "    Details:\n",
        "    {business_details}\n",
        "\n",
        "    Categorize the business clearly into one of the following statuses based on the ease or difficulty of meeting the listed requirements:\n",
        "    - targeted (highly desirable)\n",
        "    - acceptable (requirements easily met)\n",
        "    - limited (some challenges, but feasible)\n",
        "    - not acceptable (requirements too difficult to meet)\n",
        "\n",
        "    Respond with just the status.\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFOwUFRmcF-a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Initialize a dictionary to hold business statuses\n",
        "business_statuses = []\n",
        "\n",
        "# Process each business to get status\n",
        "for idx, business_name in enumerate(business_names):\n",
        "    print(f\"Evaluating status for {business_name} ({idx+1}/{len(business_names)})\")\n",
        "\n",
        "    # Extract detailed section for the business\n",
        "    pattern = rf\"## {re.escape(business_name)}(.*?)---\"\n",
        "    match = re.search(pattern, markdown_content, re.DOTALL)\n",
        "    business_details = match.group(1).strip() if match else \"No details found.\"\n",
        "\n",
        "    status_chain = (\n",
        "        {\"business_name\": lambda _: business_name, \"business_details\": lambda _: business_details}\n",
        "        | status_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    status = status_chain.invoke({}).strip()\n",
        "    business_code = random.randint(10000, 99999)\n",
        "\n",
        "    business_statuses.append({\"name\": business_name, \"code\": business_code, \"status\": status})\n",
        "\n",
        "# Append the summary table to markdown file\n",
        "with open(\"bop_guidelines.md\", \"a\") as md_file:\n",
        "    md_file.write(\"\\n## Business Categorization Summary\\n\\n\")\n",
        "    md_file.write(\"| Name | Code | Status |\\n\")\n",
        "    md_file.write(\"|------|------|--------|\\n\")\n",
        "\n",
        "    for entry in business_statuses:\n",
        "        md_file.write(f\"| {entry['name']} | {entry['code']} | {entry['status']} |\\n\")\n",
        "\n",
        "print(\"Business categorization summary successfully appended to 'bop_guidelines.md'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4aZ3C-mcv-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9020301-73f3-463c-d7d3-87797d6f3f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 libapache-pom-java\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3\n",
            "  libcommons-logging-java libcommons-parent-java libfontbox-java libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java\n",
            "  libptexenc1 libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2\n",
            "  libwoff1 libzzip-0-13 lmodern pandoc-data poppler-data preview-latex-style\n",
            "  rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration t1utils teckit tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n",
            "  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java\n",
            "  texlive-luatex pandoc-citeproc context wkhtmltopdf librsvg2-bin groff ghc\n",
            "  nodejs php python libjs-mathjax libjs-katex citation-style-language-styles\n",
            "  poppler-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf | pdf-viewer xzdec\n",
            "  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n",
            "  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl\n",
            "  texlive-latex-extra-doc texlive-latex-recommended-doc texlive-pstricks\n",
            "  dot2tex prerex texlive-pictures-doc vprerex default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 libapache-pom-java\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3\n",
            "  libcommons-logging-java libcommons-parent-java libfontbox-java libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java\n",
            "  libptexenc1 libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2\n",
            "  libwoff1 libzzip-0-13 lmodern pandoc pandoc-data poppler-data\n",
            "  preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick\n",
            "  ruby-xmlrpc ruby3.0 rubygems-integration t1utils teckit tex-common tex-gyre\n",
            "  texlive-base texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic texlive-xetex tipa xfonts-encodings xfonts-utils\n",
            "0 upgraded, 57 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 202 MB of archives.\n",
            "After this operation, 728 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.11 [753 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.11 [5,031 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [115 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm-extensions0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [25.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.10 [50.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.10 [5,114 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc-data all 2.9.2.1-3ubuntu2 [81.8 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc amd64 2.9.2.1-3ubuntu2 [20.3 MB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\n",
            "Fetched 202 MB in 7s (29.9 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 126101 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.11_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.11_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcmark-gfm0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../17-libcmark-gfm0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcmark-gfm-extensions0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../18-libcmark-gfm-extensions0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../19-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../20-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../21-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../22-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../23-ruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.10) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../24-ruby-rubygems_3.3.5-2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../25-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../26-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../27-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../28-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../29-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../30-libruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../31-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../32-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../33-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../34-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../35-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../36-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../37-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../38-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package pandoc-data.\n",
            "Preparing to unpack .../39-pandoc-data_2.9.2.1-3ubuntu2_all.deb ...\n",
            "Unpacking pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package pandoc.\n",
            "Preparing to unpack .../40-pandoc_2.9.2.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../41-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../42-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package teckit.\n",
            "Preparing to unpack .../43-teckit_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking teckit (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../44-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../45-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../46-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../47-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../48-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../49-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../50-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../51-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../52-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../53-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../54-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../55-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../56-texlive-xetex_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-xetex (2021.20220204-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Setting up libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Setting up teckit (2.5.11+ds1-1) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up texlive-xetex (2021.20220204-1) ...\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.10) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "[WARNING] Could not parse YAML metadata at line 1371 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 1722 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 2382 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 2666 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 2951 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 3540 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 4086 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 4398 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 4945 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≥ (U+2265) (U+2265) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n",
            "[WARNING] Missing character: There is no ≤ (U+2264) (U+2264) in font [lmroman10-regular]:mapping=t\n"
          ]
        }
      ],
      "source": [
        "!apt-get install pandoc texlive-xetex -y\n",
        "!pandoc bop_guidelines-10.md -o bop_guidelines_draft.pdf \\\n",
        "  --pdf-engine=xelatex \\\n",
        "  -V geometry:margin=1cm \\\n",
        "  --toc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pandoc bop_guidelines-10.md -o bop_guidelines.tex\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyBRvyz9dibo",
        "outputId": "8784a2af-782c-4393-c12e-e88dd898cb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Could not parse YAML metadata at line 1371 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 1722 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 2382 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 2666 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 2951 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 3540 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 4086 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 4398 column 1: Lexical error near \"* **Preferred:**\"\n",
            "[WARNING] Could not parse YAML metadata at line 4945 column 1: Lexical error near \"* **Preferred:**\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}